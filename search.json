[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Notes",
    "section": "",
    "text": "PPO for humans\n\n\n\n\n\n\n\nRL\n\n\nPPO\n\n\n\n\nA description of PPO as implemented in stabe-baselines 1.8.0\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n  \n\n\n\n\nGPUs for Deep Learning\n\n\n\n\n\n\n\nhardware\n\n\nbuy\n\n\n\n\nA collection of benchmarks of GPUs for Deep Learning\n\n\n\n\n\n\nJan 30, 2023\n\n\n\n\n\n\n  \n\n\n\n\nUnsupervised Anomaly Detection with Variational Autoencoders\n\n\n\n\n\n\n\npaper\n\n\n\n\nA review of papers showing how to use VAEs for unsupervised anomaly detection\n\n\n\n\n\n\nJan 16, 2023\n\n\n\n\n\n\n  \n\n\n\n\nML/AI in CNC and machining\n\n\n\n\n\n\n\npaper\n\n\n\n\nA review of papers on ML / AI approaches in machining and CNC\n\n\n\n\n\n\nJan 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Reviews - 2022-12-13 LOS\n\n\n\n\n\n\n\npaper\n\n\n\n\nPaper reviews\n\n\n\n\n\n\nDec 12, 2022\n\n\n\n\n\n\n  \n\n\n\n\nThe benefits of Matlab Campus-Wide license - webinar notes\n\n\n\n\n\n\n\nsoftware\n\n\n\n\nWebinar notes`\n\n\n\n\n\n\nNov 30, 2022\n\n\n\n\n\n\n  \n\n\n\n\nDeep Learning resources\n\n\n\n\n\n\n\nsoftware\n\n\n\n\nAn overview of software frameworks, libraries and infrastructure for AI\n\n\n\n\n\n\nNov 17, 2022\n\n\n\n\n\n\n  \n\n\n\n\nEnsemble scoring review\n\n\n\n\n\n\n\npaper\n\n\nanomaly\n\n\nscoring\n\n\nbrainstorming\n\n\n\n\nCombining multiple estimator scores into a common ensemble\n\n\n\n\n\n\nNov 14, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLOF: identifying density-based local outliers\n\n\n\n\n\n\n\npaper\n\n\nanomaly\n\n\n\n\nPaper introducing outlier detection with LOF\n\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-11-10_LOF/LOF.html",
    "href": "posts/2022-11-10_LOF/LOF.html",
    "title": "LOF: identifying density-based local outliers",
    "section": "",
    "text": "Outlier-ness is not binary, but is a degree: it is a number.\nLOF = Local Outlier Factor = average density around nearest neighbors / density around point in question (sort of):\n\nHigh LOF = more outlier\nLow LOF (around 1) = not outlier, in cluster\n\nLOF score depends on the neighbourhoods of neigbors, adapts to “density” of neighboring clusters\nMe: Not clear how it scales to high dimensions, the intuitions might be wrong\nImage:"
  },
  {
    "objectID": "posts/2022-11-10_LOF/LOF.html#details",
    "href": "posts/2022-11-10_LOF/LOF.html#details",
    "title": "LOF: identifying density-based local outliers",
    "section": "Details",
    "text": "Details\nhttps://doi.org/10.1145/335191.335388\nArticle (Breunig2000)\nBreunig, M. M.; Kriegel, H.-P.; Ng, R. T. & Sander, J.\nLOF: identifying density-based local outliers\nACM SIGMOD Record, 2000, 29, 93-104"
  },
  {
    "objectID": "posts/2022-11-14_Scoring/Scoring.html",
    "href": "posts/2022-11-14_Scoring/Scoring.html",
    "title": "Ensemble scoring review",
    "section": "",
    "text": "A quick overview of some papers about normalizing and combining scores."
  },
  {
    "objectID": "posts/2022-11-14_Scoring/Scoring.html#krieger2011-interpreting-and-unifying-outlier-scores",
    "href": "posts/2022-11-14_Scoring/Scoring.html#krieger2011-interpreting-and-unifying-outlier-scores",
    "title": "Ensemble scoring review",
    "section": "Krieger2011: Interpreting and Unifying Outlier Scores",
    "text": "Krieger2011: Interpreting and Unifying Outlier Scores\n\nInCollection (Kriegel2011)\nKriegel, H.-P.; Kroger, P.; Schubert, E. & Zimek, A.\nInterpreting and Unifying Outlier Scores\nSociety for Industrial and Applied Mathematics, 2011, 13-24\n\n\n\nDifferent (simple) regularizations and normalizations\nRegularization = 0 to infinity, with increasing values = more outlying\nNormalization = 0 to 1, with increasing values = more outlying\nTypical: Gaussian scaling\n\nis = probability (X < value) for a standard normal with mean and dev as the scores (1/2(1+erf()) formula)\nimplemented in PyOD as predict_proba(X, method=‘unify’)"
  },
  {
    "objectID": "posts/2022-11-14_Scoring/Scoring.html#zimek2014-ensembles-for-unsupervised-outlier-detection-challenges-and-research-questions",
    "href": "posts/2022-11-14_Scoring/Scoring.html#zimek2014-ensembles-for-unsupervised-outlier-detection-challenges-and-research-questions",
    "title": "Ensemble scoring review",
    "section": "Zimek2014: Ensembles for unsupervised outlier detection: challenges and research questions",
    "text": "Zimek2014: Ensembles for unsupervised outlier detection: challenges and research questions\n\nArticle (Zimek2014)\nZimek, A.; Campello, R. J. & Sander, J.\nEnsembles for unsupervised outlier detection: challenges and research questions\nACM SIGKDD Explorations Newsletter, 2014, 15, 11-22\n\n\nDiscussions, but no clear solution to take home\nSimple model selection:\n\nfirst takes the union of the top k points of all results as preliminary outliers\nThen the ensemble is composed, starting with the result that is closest to this consensus result.\nNext the remaining outlier detectors are sorted by the lowest correlation to the result of the current ensemble (initially, the ensemble consists only of one outlier detector) and test if including the next detector would improve the correlation of the ensemble result with the (preliminary) target vector (i.e., the estimated ground truth)."
  },
  {
    "objectID": "posts/2022-11-17_DLFrameworks/DLResources.html",
    "href": "posts/2022-11-17_DLFrameworks/DLResources.html",
    "title": "Deep Learning resources",
    "section": "",
    "text": "Frameworks coming with lots of pre-built tools and algorithms.\n\n\n\n\n\nMonai modules\n\n\n\nHome\nComprehensive framework for Medical Imaging\nBased on PyTorch\nThree packages:\n\nLabel: for labeling and user input. For medical experts.\nCore: AI models and training. For researchers.\nDeploy: Packaging, deployment, running\n\n\n\n\n\n\n\n\nHome\nAI platform for medical applications, from NVIDIA, with tools and pre-trained models\nAvailable as container in NGC Catalog\nApplications:\n\ngenomics\nnatural language processing (NLP)\nimaging\nmedical devices\ndrug discovery\nsmart hospitals\n\nMultiple modules:\n\nClara Parabricks: for genomics\nClara Train SDK: for AI models, training, pre-trained etc. Based on Monai"
  },
  {
    "objectID": "posts/2022-11-17_DLFrameworks/DLResources.html#libraries",
    "href": "posts/2022-11-17_DLFrameworks/DLResources.html#libraries",
    "title": "Deep Learning resources",
    "section": "Libraries",
    "text": "Libraries\nSmaller, more targeted libraries.\n\nRapids\n\n\n\nrapids.ai\n\n\n\nHome\nAccelarate generic Machine Learning algorithms in Python, with minimal code changes, based on Cuda.\n\n\n\n\nGithub repos of Rapids\n\n\n\n\n\nNVIDIA Triton Inference Server\n\n\nFront-end ynference server to serve models remotely\nHome\nSupports model backends from various frameworks: TensorRT, ONNX-Runtime, Tensorflow, PyTorch, OpenVino, pure Python, DALI, FIL (tree-based standard ML models)\n\n\n\nTriton diagram\n\n\n\nThe new Forest Inference Library (FIL) backend in Triton provides support for high-performance inference of tree-based models with explainability (SHAP values) on CPUs and GPUs. It supports models from XGBoost, LightGBM, scikit-learn RandomForest, RAPIDS™ cuML RandomForest, and others in Treelite format.\n\n\n\n\n\nNVIDIA DeepStream\n\n\n\nDeepStream architecture\n\n\n\nDeepStream SDK is a complete streaming analytics toolkit based on GStreamer for AI-based multi-sensor processing, video, audio, and image understanding\n\n\nAI toolkit for applications with streaming data: video, audio\nBased on GStreamer libraries, integrates with GStreamer plugins\nC++ and Python\nCan be used on Jetson edge devices (I worked personally on this)\n\n\n\n\nNVIDIA Tao Toolkit\n\n\nThe NVIDIA TAO Toolkit, built on TensorFlow and PyTorch, is a low-code version of the NVIDIA TAO framework that accelerates the model training process by abstracting away the AI/deep learning framework complexity. The TAO Toolkit lets you use the power of transfer learning to fine-tune NVIDIA pretrained models with your own data and optimize for inference—without AI expertise or large training datasets\n\n\n\n\nMeVisLab\n\n\nModular framework for image processing research and development with a special focus on medical imaging.\nIt allows fast integration and testing of new algorithms and the development of clinical application prototypes.\n\n\nHome\nSW library and IDE\nDetails:\n\nMeVisLab is a rapid prototyping and development platform for medical image processing and visualization. With its image processing library, it fulfills the following requirements:\n\nAble to handle large, six-dimensional images (x, y, z, color, time, user-defined).\nOffers easy ways to develop new algorithms or changing/improving existing ones in a modular C++ interface, perfect for a fast-developing research area.\nOffers easy ways of combining algorithms to algorithm pipelines and networks.\nFast and easy integration into clinical environments due to standard interfaces, for example to DICOM.\nFair performance for clinical routine due to a page-based, demand-driven approach in the image processing.\n\nBeside general image processing algorithms and visualization tools, MeVisLab includes advanced medical imaging modules for segmentation, registration, volumetry and quantitative morphological, and functional analysis.\nBased on MeVisLab, several clinical prototypes have been developed, including software assistants for neuro-imaging, dynamic image analysis, surgery planning, and vessel analysis.\nThe implementation of MeVisLab makes use of a number of well known third-party libraries and technologies, most importantly the application framework Qt, the visualization and interaction toolkit Open Inventor, the scripting language Python, and the graphics standard OpenGL. In addition, modules based on the Insight ToolKit (ITK) and the Visualization ToolKit (VTK) are available.\n\n\n\n\n\nNVIDIA Digits\n\n\nInteractive Deep Learning GPU Training System\nHome\nTechnical Documentation\nAbout:\n\n\n\nDIGITS is not a framework\nDIGITS is a wrapper for NVCaffe and TensorFlow, which provides a graphical web interface to those frameworks rather than dealing with them directly on the command-line\nDesign, train and visualize deep neural networks for image classification, segmentation and object detection using Caffe, Torch and TensorFlow\nPre-trained models from the DIGITS Model Store\nPerform hyperparameter sweep of learning rate and batch size\nSchedule, monitor, and manage neural network training jobs, and analyze accuracy and loss in real time\nImport a wide variety of image formats and sources with DIGITS plug-in\nScale training jobs across multiple GPUs automatically\n\n\n\nAvailable in NGC: https://catalog.ngc.nvidia.com/orgs/nvidia/containers/digits\nNotes\n\nRather old (started in 2015), might be out of touch with recent developments\nLast container version on NGC is from September 2021\n\n\n\n\n\nPyTorch, Tensorflow, Matlab etc\n\nAll available on the NGC Catalog"
  },
  {
    "objectID": "posts/2022-11-17_DLFrameworks/DLResources.html#infrastructure",
    "href": "posts/2022-11-17_DLFrameworks/DLResources.html#infrastructure",
    "title": "Deep Learning resources",
    "section": "Infrastructure",
    "text": "Infrastructure\nLow-level technology to make all the magic run\n\nDocker containers\n\nWhat is a container\nIn practice, mostly used for deployment / builing in isolated environments, but not necessarily day-to-day development\nDocker vs Virtual Machine\n\n\n\nDocker vs. Virtual machines\n\n\n\n\n\n\nJupyter Hub server\n\n\nHome\nEnabling multiple users to work simultaneously on their notebooks, from client browsers\n\n\n\n\nNVIDIA NGC Catalog\n\nCatalog of GPU-enabled Docker containers for AI\nHome\nPopular container collections:\n\nNvidia AI collection:\n\n\nDeep Learning Frameworks: Updated monthly, PyTorch and TensorFlow\nRAPIDS: Accelerates end-to-end data science and analytics pipelines entirely on GPUs.\nTensorRT: Takes a trained network and produces a highly optimized runtime engine that performs inference for that network.\nTAO: A python-based AI toolkit for taking purpose-built pre-trained AI models and customizing them with your own data. Add all 3 TAO containers in the entities tab.\nTriton: An open-source software to deploy trained AI models from any framework, on any GPU- or CPU-based infrastructure in the cloud, data center, or embedded devices.\nDeepStream: This SDK delivers a complete streaming analytics toolkit for AI based video and image understanding and multi-sensor processing.\nRIVA: A GPU-accelerated SDK for building speech applications that are customized for your use case and deliver real-time performance. Include RIVA Clients and RIVIA Speech skills\n\n\n\n\n\n\n\nMisc\n\nGoogle Colab notebooks on local runtime container:\n\nCreate your own GPU accelerated Jupyter Notebook Server for Google Colab using Docker\nJupyter local runtime for Google Colab with CUDA and BERT"
  },
  {
    "objectID": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html",
    "href": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html",
    "title": "The benefits of Matlab Campus-Wide license - webinar notes",
    "section": "",
    "text": "Title: The benefits of Matlab Campus-Wide license\n\nwith a focus on AI and ML\n\nContents:"
  },
  {
    "objectID": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#online-courses",
    "href": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#online-courses",
    "title": "The benefits of Matlab Campus-Wide license - webinar notes",
    "section": "Online courses",
    "text": "Online courses\n\nMathworks portal: University has dedicated portal\nCourses homepage: matlabacademy.mathworks.com\n\nOnRamp courses: 13 courses, 23 hours\n\nprior to the first classroom lectures\ndon’t waste time teach basics of syntax, use online course\nMatlab, Simulink, AI, ML DL, RL Onramps\nSignal Processing\n\nInDepth: free for CWL, 13 courses, 100 hours"
  },
  {
    "objectID": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#matlab-online",
    "href": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#matlab-online",
    "title": "The benefits of Matlab Campus-Wide license - webinar notes",
    "section": "Matlab Online",
    "text": "Matlab Online"
  },
  {
    "objectID": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#live-scripts",
    "href": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#live-scripts",
    "title": "The benefits of Matlab Campus-Wide license - webinar notes",
    "section": "Live Scripts",
    "text": "Live Scripts\n\ninclude controls, like in Jupyter notebooks\nmuch less files in one project\nMatlab on mobile platforms (phone)\n\naccess sensors (e.g. step counter)"
  },
  {
    "objectID": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#matlab-grader",
    "href": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#matlab-grader",
    "title": "The benefits of Matlab Campus-Wide license - webinar notes",
    "section": "Matlab Grader",
    "text": "Matlab Grader\n\n90% of tests can be implemented online instead of paper & pen\nsome effort:\n\nclear description, form of solution\nLatex based support\nprepare template, piece of code with empty parts\nprepare reference solution\nMG compares student solution with reference sol\nprovide testing criteria\ncan add .m files or .p files\ntest types:\n\ncompare variable with correct result\nmatlab code for own testing\n\ncan be implemented in Moodle!\n\nIt is possible to compare students’ solutions among each other\nCan later modify come and evaluate them again\nCan export results in excel sheet format"
  },
  {
    "objectID": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#ml-dl-ai-support",
    "href": "posts/2022-11-30-MatlabWebinarAI/MatlabWebinarAI.html#ml-dl-ai-support",
    "title": "The benefits of Matlab Campus-Wide license - webinar notes",
    "section": "ML, DL, AI support",
    "text": "ML, DL, AI support\n\n\nsupports entire workflow:\n\ndata preparation, generation, cleaning\nAI modeling: design, tuning, train, compatib with TF and pytorch (yeah sure )\nSystem design (simulink, simscape, validation)\nDeployment & code generation\n\nUse DL Toolbox examples, courses\nExamples:\n\nWritten character recognition\nClassification Learner tool\n\nmany algorithms available\n\nTransfer Learning with Deep Network Designer\n\n\nbuilt-in pretrain networks\n\nParallel computing support (parfor)"
  },
  {
    "objectID": "posts/2022-12-12_LOS-Reviews/LOS_Reviews.html",
    "href": "posts/2022-12-12_LOS-Reviews/LOS_Reviews.html",
    "title": "Paper Reviews - 2022-12-13 LOS",
    "section": "",
    "text": "A quick overview of some papers mentioned in LOS Seminar 2022-12-13"
  },
  {
    "objectID": "posts/2022-12-12_LOS-Reviews/LOS_Reviews.html#xie2013-on-a-nonlinear-generalization-of-sparse-coding-and-dictionary-learning",
    "href": "posts/2022-12-12_LOS-Reviews/LOS_Reviews.html#xie2013-on-a-nonlinear-generalization-of-sparse-coding-and-dictionary-learning",
    "title": "Paper Reviews - 2022-12-13 LOS",
    "section": "Xie2013: On A Nonlinear Generalization of Sparse Coding and Dictionary Learning",
    "text": "Xie2013: On A Nonlinear Generalization of Sparse Coding and Dictionary Learning\n\n\na novel framework for sparse coding and dictionary learning for data on a Riemannian manifold, and it shows that the existing sparse coding and dictionary learning methods can be considered as special (Euclidean) cases of the more general framework proposed here.\n\n\ndata and features are often presented as points on known Riemannian manifolds, e.g., the space of symmetric positive-definite matrices (Fletcher & Joshi, 2007), hyperspheres for parameterizing square-root densities (Srivastava et al., 2007), Stiefel and Grassmann manifolds (Mardia & Jupp, 1999), etc..\n\nManifold-based sparse coding.\nReformulates sparsity in affine way, reformulates sparse coding and dictionary learning\nExample: dictionary learning on the sphere\nStrongly mathematical"
  },
  {
    "objectID": "posts/2023-01-07-CNC/CNC.html",
    "href": "posts/2023-01-07-CNC/CNC.html",
    "title": "ML/AI in CNC and machining",
    "section": "",
    "text": "Machine Learning for industrial applications: A comprehensive literature review\n\\(5/5 \\star\\)\n\nArticle (Bertolini2021)\nBertolini, M.; Mezzogori, D.; Neroni, M. & Zammori, F.\nMachine Learning for industrial applications: A comprehensive literature review Expert Systems with Applications, 2021, 175, 114820\n\n\nGood review paper, classifies papers by Application Domain and by ML algorithm.\nNot only for CNC / machining, but many types of industrial applications\nLarge number of papers surveyed\nHot and not-so-hot topics, clustered:\n\nUsing these metrics, five main clusters can be identified. These are:\n\nQuestion Marks (Low Age and Negative Trend) – Recently introduced topics, that have not got a follow-up, yet. Thermography (THER), Cyber-Physical Systems (CPS), and Design For (D4) belong to this category.\nHot Topics (Low Age and Negative Positive Trend) – Very recent topics of booming interest. At present, none of the keywords properly belong to this category. Yet, Additive Manufacturing (ADD_MN), Prediction & Prognostic (PR_PR), and Industry 4.0 (I4.0) are those who come closest to this category. For this reason, they have been labeled as ‘new promises’.\nConsolidated (Medium Age and Stable Trend) – Not recent topics, which are still studied, but without the initial spike of interests. Topics such as Supply Chain Management (SCMI), Flexible Manufacturing Systems (FMS), Inventory Control (INV_CTRI), and Tool Monitoring (TLL_MN) belong to this category.\nStars (High Age and Positive Trend) – Old and consolidated topics that are still attracting increasing research interest. Topics such as Diagnosis and Fault Detection (DG_FLT), Manufacturing Process (MN_PR), Intelligent Manufacturing (INT_MN), and Big Data analysis (BD_DM) certainly belong to this class. Probably, Simulation (SIM) and the Internet of Things (IoT) are on their way to become stars.\nObsoletes (High Age and Negative Trend) – Old topics that have never received much scientific interest and that have almost disappeared from the technical literature. Due to the recent introduction of ML, for operation management, no keywords can be classified as obso­ letes yet. However, Order Management (OM) and, probably, also Feature Extraction (FT_EX) are moving toward this class.\n\n\n\n\n\n …\n\nAnomaly detection examples:\n\n\nSample variables commonly used in datasets:\n\nTable 4, which provides some indications concerning the variables that are commonly used per each application domain and sub-area\n\n\n\n\n\n\nMaintenance management: keep assets and machines at a full operating state\n\nFailure Mode Analysis: Faults detection and classification. Easily interpreted as a prediction task, where historical data are collected on the production floor, and faulty and non-faulty events are used as ground-truth data against which a prediction model can be trained (NN, SVM)\nCondition Monitoring: the most common applications concern condition monitoring of rotating mechanical systems and rolling bearings. The problem is solved using vibrations and/or acoustic signals as classifiers inputs.\nDowntime Minimization: Plan predictive maintainance operations smartly, to minimize costs.\n\nQuality Management\n\nDefects’ Detection and Classification\n\nUnbalanced datasets\n\nVisual quality inspection: detect defects by image classification\n\nProduction Planning & Control (PPC)\n\nPerformance Prediction and Optimization: order acceptance policy, optimal sequence of technical steps, reduce electricity consumption, optimize parameters\nScheduling: NP-hard, select dispatching rules, dynamic scheduling based on conditions\nProcess Control: Reinforcement Learning to automate a process; optimizing parameters for safe behavior in non-conforming operations.\n\nSupply Chain Management: logistics\n\nModeling and Coordination: Reinforcement Learning\nDemand Forecasts: prediction models\nInventory Control:\n\ncomplex modeling of supply chains, not easy, RL is a good fit here\n\n\nOther things: - noisy data is common, many techniques used to clean it - unbalanced data - low interpretability, with Deep NNs\n\n\n\n\n\nSmart Machining Process Using Machine Learning: A Review and Perspective on Machining Industry (2018) (Kim et al. 2018)\n\\(3/5 \\star\\)\nContains a listing of many machining problems where machine learning algorithms have been used in machining.\n\nMachine processes: General, milling, drilling\nPurpose: Tool wear and breakage, predict energy consumption, surface roughness prediction, process parameter optimization\nAlgorithms: SVM and SVR, various NNs, Random forests, linear regression, k-NN, depending on task\n\n\n\n\n\nData Driven Cutting Tool Fault Diagnosis System Using Machine Learning Approach: A Review (Tambake, Deshmukh, and Patange 2021)\n\\(2/5 \\star\\)\n\nPoorly written, but contains a list of papers on fault detection"
  },
  {
    "objectID": "posts/2023-01-07-CNC/CNC.html#technical-papers",
    "href": "posts/2023-01-07-CNC/CNC.html#technical-papers",
    "title": "ML/AI in CNC and machining",
    "section": "Technical papers",
    "text": "Technical papers\n\nOrdas2017\nWear Characterization of the Cutting Tool in Milling Processes using Shape and Texture Descriptors (PhD thesis, 2017)(García-Ordás 2017)\n\nPhD thesis which proposes and evaluates some image-based descriptors to characterize tool wear, using a cheap Raspberry Pi + camera setup which captures images of the cutting tool.\nInvestigative / no remarkable results.\n\n\n\n\nPapandrea2020\nSurface roughness diagnosis in hard turning using acoustic signals and support vector machine: A PCA-based approach (Papandrea et al. 2020)\n\nSupervised Learning\nSurface roughness classification, based on acoustic signals during cutting.\nUse STFT followed by PCA per coefficients, and SVM for classification.\nTested on CNC, with stock microphone\nSome complicated experimental machining setups, several parameters in the process (rotating speed, feed rate). The experimental setups depend on many factors.\nResults weak. Some PCA coeffs are correlated with roughness, and can be clustered consistently into 3 groups, which can then be identified in test sets.\nMore investigative / basic research, no remarkable results.\n\n\n\n\n\nCho2005\nTool breakage detection using support vector machine learning in a milling process (Cho et al. 2005)\n\nArticle (Cho2005)\nCho, S.; Asfour, S.; Onar, A. & Kaundinya, N.\nTool breakage detection using support vector machine learning in a milling process\nInternational Journal of Machine Tools and Manufacture, 2005, 45, 241-249\n\n\nSupervised Learning\nDetect two types of tool breakage: shank breakage and flute breakage\nCutting forces + power consumption (proportional with force) + SVRegression => detect flute breakage\nIdea:\n\nIn normal operation, model the cutting force / normal power consumption based on spindle speed, feed rate, depth of cut with SVRegression (alternative: with multiple linear regression)\nDetection: if actual measured values deviate a lot from model predictions (by a threshold), we have a breakage.\n\nSVR is hard to parameterize!\n\n\n\n\nLi2017\nAn Ensemble Deep Convolutional Neural Network Model with Improved D-S Evidence Fusion for Bearing Fault Diagnosis (Li et al. 2017)\n\nArticle (Li2017)\nLi, S.; Liu, G.; Tang, X.; Lu, J. & Hu, J.\nAn Ensemble Deep Convolutional Neural Network Model with Improved D-S Evidence Fusion for Bearing Fault Diagnosis\nSensors, Multidisciplinary Digital Publishing Institute, 2017, 17, 1729\n\n\n\nSupervised Learning\nFor bearing fault detection, with deep neural networks\nUsing Dempster–Shafer (D-S) evidence theory for sensor fusion, improves it with custom modifications\nRaw signals: acceleration and vibration from 2 sensors\nData preprocessing: sliding windows, subband, RMS, reshape to square images\nSmall CNN trained in images, used as feature extractors\nCNN outputs are fused with the Improved D-S scheme\n\n\n\n\nKankar2011\nFault diagnosis of ball bearings using machine learning methods (Kankar, Sharma, and Harsha 2011)\n\nArticle (Kankar2011)\nKankar, P. K.; Sharma, S. C. & Harsha, S. P.\nFault diagnosis of ball bearings using machine learning methods\nExpert Systems with Applications, 2011, 38, 1876-1886\n\n\nSupervised Learning\nDetect defects and in ball bearings based on vibration data collected with accelerometers\n2D acceleration signals (horizontal and vertical)\nRecording length = about 0.5 to 1 second\n5 classes:\n\nHealthy bearings (HB).\nBearing with outer race crack (BORC).\nBearing with rough inner race surface (BRIR).\nBall with corrosion pitting (BCP).\nCombined bearing component defects (CBD)\n\nManual features (range, mean, kurtosis etc):\n6 features from horizontal + 6 features vertical + speed + “number of loader” =< 14 features per instance\nFeature selection step (not clear how)\nResults: accuracy about 70%\n\n\n\n\n\nOng2019\nTool condition monitoring in CNC end milling using wavelet neural network based on machine vision (Ong, Lee, and Lau 2019)\n\nArticle (Ong2019)\nOng, P.; Lee, W. K. & Lau, R. J. H.\nTool condition monitoring in CNC end milling using wavelet neural network based on machine vision\nThe International Journal of Advanced Manufacturing Technology, 2019, 104, 1369-1379\n\n\nNice introduction and review:\n\n\nFor the indirect method of tool condition monitoring, there are considerably numerous studies attempting to correlate the relationship between the machining parameters with tool wear\n\ntool wear detection with visual and non-visual signals (cutting force, sound, vibration)\ntool wear estimation by visually analyzing the surface of the machined part\n\nUe a special type of NN, Wavelet Neural Network, to predict flank wear. WNN is just their quirk.\nWNN are a generalized form of RBF-NN, with wavelet activation functions\nUse images of the tool itself and/or the surface of the machined part\nImage preprocessing of the worn region of the tool:\nimg/2023-01-09-12-54-18.png\nNN architecture used. Shallow with 1 hidden layer:\n\nDataset: just 126 images\nResults: good predictions by pretty much all methods compared.\n\n\n\n\n\nHahn2021\n\nArticle (Hahn2021)\nHahn, T. V. & Mechefske, C. K.\nSelf-supervised learning for tool wear monitoring with a disentangled-variational-autoencoder\nInternational Journal of Hydromechatronics, Inderscience Publishers, 2021, 4, 69-98\n\n\nfrom PapersWithCode\n\nA disentangled-variational-autoencoder, with a temporal convolutional neural network, is used to model and trend tool wear in a self-supervised manner, and anomaly detection is used to make predictions from both the input and latent spaces\n\nEnd-to-end Deep Learning\nTemporal CNN:\n\ncausal and dilated convolutions\n\n\nDisentangled-VAE:\n\njust a normal VAE with a value of \\(\\beta\\) higher than one in the cost function (?):\n\n\nTuning the hyper-parameter β, to a value larger than one, can enable the factors to disentangle such that each coding only represents one factor at a time. Thus, greater interpretability of the model can be obtained. As such, the disentangled-VAE is also called a β-VAE\n\n\nLatent space anomaly detection: detect anomaly in the latent variables, i.e. out-of-distribution. Several methods available. KL-divergence.\nDatasets:\n\nUC Berkeley Milling dataset. Freely available, small.\nActual data from industry partener: 27 days, 5600 parts, annotated. Unavailable, large.\n\nProcess:\n\n\nPreprocessing:\n\nselect middle part of recording (stable cutting)\nsliding window\nMinMax scaling to \\([0,1]\\)\neach window labeled by hand (healthy / degraded / failed)\nrandomly group windows into train/test sets\n\nStandard training\nResults:\n\nPR-AUC 50% for failed vs non-failed on the UC Berkeley dataset (PR-AUC = Precision-Recall AUC)\n\n4% PR-AUC on the industrial dataset ????!!!!\n\n\n\n\n\n\nMey2020\n\nInProceedings (Mey2020)\nMey, O.; Neudeck, W.; Schneider, A. & Enge-Rosenblatt, O.\nMachine Learning-Based Unbalance Detection of a Rotating Shaft Using Vibration Data\n2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA), 2020, 1, 1610-1617\n\n\nFrom PapersWithCode\nCode available in Github here\nUses (introduces) Fraunhoffer unbalance dataset\n\n\n\nGoal: try do detect if unbalance is present on the rotating shaft\nIntroduces a new dataset (Fraunhoffer unbalance dataset)\nMethods:\nCNN on raw sensor data (windowed), 2-4 convs\n\n90% accuracy, weaker for small unbalance and particualar speeds (resonances?)\n\nFully-connected MLP in FFT data\n\nsimilar to CNN results\n\nRandom Forests on automatically extracted timeseries features (again with tsfresh)\n\nsimilar (?)\n\nHidden Markov Models on MFCC\n\nConclusions:\n\n\nThe largest unbalance could be detected by all algorithms with almost perfect prediction accuracy, even if only 3 characteristic values per sample were used for the classification.\nWith the smaller unbalances, on the other hand, wider variations between the different approaches were found.\nThe best way to classify the dataset was to use an FC network with two hidden layers, which received the scaled FFT-transformed vibration data as input.\nMeasured on the entire evaluation dataset, 98.6 % of the cases could be classified correctly."
  },
  {
    "objectID": "posts/2023-01-07-CNC/CNC.html#datasets",
    "href": "posts/2023-01-07-CNC/CNC.html#datasets",
    "title": "ML/AI in CNC and machining",
    "section": "Datasets",
    "text": "Datasets\n\nCRWU Bearing Dataset\n\n\nLink here\n\n\nVibration data was collected using accelerometers, which were attached to the housing with magnetic bases. Accelerometers were placed at the 12 o’clock position at both the drive end and fan end of the motor housing. During some experiments, an accelerometer was attached to the motor supporting base plate as well. Vibration signals were collected using a 16 channel DAT recorder, and were post processed in a Matlab environment. All data files are in Matlab (*.mat) format. Digital data was collected at 12,000 samples per second, and data was also collected at 48,000 samples per second for drive end bearing faults. Speed and horsepower data were collected using the torque transducer/encoder and were recorded by hand.\n\n\n\n\nUC Berkeley Milling dataset, NASA\n\nLink here\nPapersWithCode: Link here\nKaggle: Link here\n\n\nExperiments on a milling machine for different speeds, feeds, and depth of cut. Records the wear of the milling insert, VB. The data set was provided by the UC Berkeley Emergent Space Tensegrities (BEST) Lab.\n\n\n\n\n\nBosch CNC dataset\n\nLink here\nPapersWithCode: Link here\nDescribed in:\n\nArticle (Tnani2022)\nTnani, M.-A.; Feil, M. & Diepold, K.\nSmart Data Collection System for Brownfield CNC Milling Machines: A New Benchmark Dataset for Data-Driven Machine Monitoring\nProcedia CIRP, 2022, 107, 131-136\n\nbrownfield deployment: new hardware or software that must coexist with legacy IT systems\nA whole procedure for collecting data and analyzing on the fly\n\n\n\nSensor mounting\n\n\n\n\nDataset:\n\nvibration data collected with accelerometer sensors mounted to the rear end of the spindle housing\ncollected over 2 years\nthree diferent machines\nsampling rate 2 kHz, argue that it is enough for anomalies\nsmart mining system, otherwise would need 4GB data per day\n15 different operations recorded, with different parameterizations\nlabeled good vs bad (normal vs anomaly)\n\nProcessing:\n\nTsfresh: automatic package to extract standard features from time series, open source, here, paper here\n\nReal world challenges:\n\nproblems when changing tools => some recordings are bad\nunbalanced data (815 to 35)\nnormal wear of tools, hydraulic issues, incorrect settings => some variability\n15 different operations recorded, with different parameterizations => difficult to predict health status, it depends on all params\n\n\nanomaly can be detected in frequencies which are integer multiples of the spindle speed ()\n\nanomalies better detected in frequency domain\n\n\n\n\n\nIMS Bearing Dataset, Cincinatti, NASA\n\nLink here, no.4\nPapersWithCode: Link here\nKaggle: Link here\nAccelerometer data in turning bearings, recorded until they fail\n\n\nFour bearings were installed on a shaft. The rotation speed was kept constant at 2000 RPM by an AC motor coupled to the shaft via rub belts. A radial load of 6000 lbs is applied onto the shaft > and bearing by a spring mechanism. All bearings are force lubricated. Rexnord ZA-2115 double row bearings were installed on the shaft as shown in Figure 1. PCB 353B33 High Sensitivity Quartz ICP accelerometers were installed on the bearing housing (two accelerometers for each bearing [x- and y-axes] for data set 1, one accelerometer for each bearing for data sets 2 and 3). Sensor placement is also shown in Figure 1. All failures occurred after exceeding designed life time of the bearing which is more than 100 million revolutions.\n\n\n\nFraunhoffer unbalance dataset\n\nLink here\nPapersWithCode: Link here\nKaggle: Link here\nUsed by (Mey et al. 2020)\nNot CNC\nA vibrating drive train (DC motor, shaft roller bearing)\nUnbalances of different weights and radii are attached to the shaft\n\n\n\nThis dataset contains vibration data recorded on a rotating drive train. This drive train consists of an electronically commutated DC motor and a shaft driven by it, which passes through a roller bearing. With the help of a 3D-printed holder, unbalances with different weights and different radii were attached to the shaft. Besides the strength of the unbalances, the rotation speed of the motor was also varied. This dataset can be used to develop and test algorithms for the automatic detection of unbalances on drive trains. Datasets for 4 differently sized unbalances and for the unbalance-free case were recorded. The vibration data was recorded at a sampling rate of 4096 values per second. Datasets for development (ID “D[0-4]”) as well as for evaluation (ID “E[0-4]”) are available for each unbalance strength. The rotation speed was varied between approx. 630 and 2330 RPM in the development datasets and between approx. 1060 and 1900 RPM in the evaluation datasets. For each measurement of the development dataset there are approx. 107min of continuous measurement data available, for each measurement of the evaluation dataset 28min. Details of the recorded measurements and the used unbalance strengths are documented in the README.md file\n\n\nEach csv file contains:"
  },
  {
    "objectID": "posts/2023-01-16-VAE_Anomaly_Detection/VAEAnomalyDetection.html",
    "href": "posts/2023-01-16-VAE_Anomaly_Detection/VAEAnomalyDetection.html",
    "title": "Unsupervised Anomaly Detection with Variational Autoencoders",
    "section": "",
    "text": "Variational Autoencoder based Anomaly Detection using Reconstruction Probability\n\nInProceedings (An2015)\nAn, J. & Cho, S.\nVariational Autoencoder based Anomaly Detection using Reconstruction Probability\n2015\n\n\nThe algorithm:\n\nVAEs learn a distribution of the inputs\nThe latent distribution \\(p(z)\\) acts as a prior (in Bayesian terms), and is the multivariate standard normal and isotropic (i.e. separable, covariance matrix is diagonal)\n\\(f(x)\\) is the encoder function\n\\(g(z)\\) is the decoder function\nThe decoder function \\(g(z)\\) maps the distribution of the latent variable \\(z\\) into an output distribution \\(p(x|z)\\) which should resemble the original distribution of \\(x\\)\nDuring reconstruction, when we sample a single latent variable \\(z\\), we reconstruct a single vector \\(\\hat{x}\\), so we have a single sample of the output distribution \\(p(x|z)\\)\nIdea for using Reconstruction Probability as an anomaly measure:\n\nsample multiple latent variables \\(z^k\\), and for each of them reconstruct the vector \\(\\hat{x}^k\\)\nuse all the vectors \\(\\hat{x}^k\\) to estimate the probability \\(p(x|z)\\), and then compute the likelihood that the original input \\(x\\) comes from this distribution\nassuming \\(p(x|z)\\) is a an isotropic normal distribution, we just compute the mean \\(\\mu = E \\lbrace \\hat{x} \\rbrace\\) and covariance matrix \\(\\Sigma\\) (diagonal, so basically we compute the variance \\(\\sigma_i^2\\) per entry of the vector)\nthe log-likelihood that the original \\(x\\) is generated by this distribution amounts to a weighted \\(\\ell_2\\) norm:\n\\[L(x) = \\sum_i \\frac{(x_i - \\mu_i)^2}{\\sigma_i^2}\\]\nwe use this as an anomaly score: small value = more anomaly, large value = more normal\nsmall value => anomaly, because \\(x\\) does not fit the output probability \\(p(x|z)\\)\n\nBetter than normal AE, because the variances are taken into account\nPerhaps the variances \\(\\sigma_i^2\\) can be used as indicators for feature selection?\n\nor are they just similar to the clones values based on the input variances\n\n\n\n\n\nContinual Learning for Anomaly Detection with Variational Autoencoder\n\nInProceedings (Wiewel2019)\nWiewel, F. & Yang, B.\nContinual Learning for Anomaly Detection with Variational Autoencoder\nICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019, 3837-3841\n\n\nUse the full loss function as anomaly score, which includes the reconstruction error and the KL distance between the distribution of \\(z\\) and the standard normal prior \\(p(z)\\)\n\n\nthe so called evidence lower bound (ELBO): \n\n\nWhile [4, 5, 6, 7] use the reconstruction probability E q φ (z|x i ) [ln p θ (x i |z)] as the anomaly score, we use the ELBO as the anomaly score because it gives slightly better results in our experiments.\n\n\nThe “reconstruction probability” used in An2015 is just the first part of the loss function (ELBO), why not use the full loss, since this is what the model was trained to minimize\n\n\n\n\n\nArticle (Yao2023)\nYao, Y.; Ma, J. & Ye, Y.\nRegularizing autoencoders with wavelet transform for sequence anomaly detection\nPattern Recognition, 2023, 134, 109084\n\n\n\n\nUse a custom loss function which includes filtering with DWT\nLearn the regularization parameter \\(\\lambda\\) which balances between AE loss and fixed DWT error\nOnly for training. In production, only AE used, as normal.\nEmpirical, non-reliable, DWT features\nIdea: Learn less the vectors which are less modified by DWT\n\nwhen second term is close to 0 (i.e. input vector unchanged by DWT filtering), \\(\\lambda\\) becomes close to 1, which reduces the influence of the AE loss, so the AE will learn less about these vectors\nso these vectors will be reconstructed more poorly, so more likely to be considered outliers\na way to make some inputs more likely to be declared outliers: vectors untouched by DWT filtering are learned less, so more likely to be outliers\n\nAfterthoughts:\n\nWhat if we multiply somehow two learnables? i.e. \\(\\lambda \\cdot \\| AE loss \\|\\), or \\(AE1 loss \\cdot AE2 loss\\). Which learns faster?\nIf one NN learns first (e.g. \\(\\lambda\\)), it will reduce the incentive for the other one to learn.\nWhat if \\(\\lambda\\) adapts much slower than the AE? \\[(1 - \\lambda) AE_{loss}  + \\lambda Const\\]\nAE loss drops first, then lambda will learn much later if the input is an outlier or not:\n\nif AE loss is small, \\(\\lambda\\) will be close to 1\nif AE loss is large, \\(\\lambda\\) will be close to 0\njust an indirect reflection of AE loss / C ?\n\nTwo NNs in competition. Does it matter which one learns first?\nOutlier detection based on speed of learning?\n\n\n\n\n\n\nInProceedings (Lappas2021)\nLappas, D.; Argyriou, V. & Makris, D.\nFourier Transformation Autoencoders for Anomaly Detection\nICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, 1475-1479\n\n\n\nAugment input vector with Fourier transform, real and imaginary parts\nLearn three coders, for each part\nConcatenate the latent variables\nA single decoder, which produces the real and imaginary parts\nArchitecture:\n\n3N => 3L => 2N\n\nY’ to X’ means what?? “Another mapping”\n\n\n\n\n\nTechReport (Choi2023)\nChoi, J.; Park, J.; Japesh, A. & Adarsh\nA Subspace Projection Approach to Autoencoder-based Anomaly Detection\narXiv, arXiv, 2023\n\n\n\nInformation theoretic interpretation (MIMO), but not sure if useful at all\nPractically: evaluate reconstruction error only on the subspace of the least significant eigenvectors of the error vectors\n\nIf error is large => outlier, if small, normal\n\nJust another example of weighted \\(\\ell_2\\) norm\n\nhere is in the space of the eigenvectors, inversely prop to variance (eigenvalues) (here just with 0, 1 binary selection)\nhere it is the covariance matrix of all errors, since for AE we have a 1-to-1 input to output (single output vector)\nfor VAE, we have the same idea, but the covariance matrix is per input vector, since we have 1-to-many (one input, multiple outputs) (see An2015)"
  },
  {
    "objectID": "posts/2023-01-30-GPU_for_DL/GPU_for_DL.html",
    "href": "posts/2023-01-30-GPU_for_DL/GPU_for_DL.html",
    "title": "GPUs for Deep Learning",
    "section": "",
    "text": "Link: https://lambdalabs.com/gpu-benchmarks\n\n\n\n\n\nLink: https://www.aime.info/en/blog/deep-learning-gpu-benchmarks-2021/\n\n\n\n\nLink: https://bizon-tech.com/gpu-benchmarks/NVIDIA-RTX-3090-vs-NVIDIA-RTX-A6000-vs-NVIDIA-RTX-A5000/579vs585vs605"
  },
  {
    "objectID": "posts/2023-11-08-PPO_for_humans/PPO_for_humans.html",
    "href": "posts/2023-11-08-PPO_for_humans/PPO_for_humans.html",
    "title": "PPO for humans",
    "section": "",
    "text": "For PPO, we have two neural networks:\n\nthe action network action_net\nthe value network value_net\n\n\n\n\nOverview of the Action Net\n\n\n\n\n\n\n\nOverview of the Value Net\n\n\nBoth networks are joined together in a single PyTorch network object, whose forward() function (the forward pass) is the following (from /data/venv/cnc-rl/lib/python3.11/site-packages/stable_baselines3/common/policies.py):\ndef forward(self, obs: th.Tensor, deterministic: bool = False) -> Tuple[th.Tensor, th.Tensor, th.Tensor]:\n    \"\"\"\n    Forward pass in all the networks (actor and critic)\n\n    :param obs: Observation\n    :param deterministic: Whether to sample or use deterministic actions\n    :return: action, value and log probability of the action\n    \"\"\"\n    # Preprocess the observation if needed\n    features = self.extract_features(obs)\n    if self.share_features_extractor:\n        latent_pi, latent_vf = self.mlp_extractor(features)\n    else:\n        pi_features, vf_features = features\n        latent_pi = self.mlp_extractor.forward_actor(pi_features)\n        latent_vf = self.mlp_extractor.forward_critic(vf_features)\n    # Evaluate the values for the given observations\n    values = self.value_net(latent_vf)\n    distribution = self._get_action_dist_from_latent(latent_pi)\n    actions = distribution.get_actions(deterministic=deterministic)\n    log_prob = distribution.log_prob(actions)\n    actions = actions.reshape((-1, *self.action_space.shape))\n    return actions, values, log_prob"
  },
  {
    "objectID": "posts/2023-11-08-PPO_for_humans/PPO_for_humans.html#ppo-training",
    "href": "posts/2023-11-08-PPO_for_humans/PPO_for_humans.html#ppo-training",
    "title": "PPO for humans",
    "section": "PPO training",
    "text": "PPO training\nThe main loop in PPO consists of two steps:\n\nRepeat\n\nRollout\n\nplay simulations with current policy and collect rewards\ndoesn’t update anything\nit’s here where distribution sampling is done, during simulations\n\nTrain\n\ntrain neural networks according to PPO policy, using the data recorded during the rollout stage\ndistribution is not sampled here, but it needs to recompute the probability of the actions recorded during collection\n\n\n\nThe general idea of PPO training is:\n\nDuring rollout, collect the cumulative reward (i.e. value) out of every state, to act like a ground truth\n\nThis uses the current policy, i.e. current Action Net, when sampling actions\nRecord all the tuples (state, action taken, cumulative reward)\n\nCompute the estimated value of the same states with the Value Net\nCompare and update:\n\nlook back on all the (state, action taken, cumulative reward) tuples collected, and:\nfor actions leading to states where the Value Net output is larger than observed ground truth value, decrease the probability of those actions (i.e. we overestimated those actions’ worth, compared to ground truth)\nfor actions leading to states where the Value Net output is smaller than observed ground truth value, increase the probability of those actions (i.e. we underestimated those action’ worth, compared to ground truth)\n\n\nThe equilibrium state, when both Action Net and Value Net are fully converged, is when the cumulative rewards collected in the rollout stage, with the current Action Net (current policy), are identical to those states’ values as computed by the Value Net."
  },
  {
    "objectID": "posts/2023-11-08-PPO_for_humans/PPO_for_humans.html#sampling-mechanism",
    "href": "posts/2023-11-08-PPO_for_humans/PPO_for_humans.html#sampling-mechanism",
    "title": "PPO for humans",
    "section": "Sampling mechanism",
    "text": "Sampling mechanism\nSampling depends on how the policy (action probability distribution) is parameterized.\nThe underlying distributions are the ones from PyTorch (see below, from /data/venv/cnc-rl/lib/python3.11/site-packages/stable_baselines3/common/policies.py):\nfrom torch.distributions import Bernoulli, Categorical, Normal\n  def _get_action_dist_from_latent(self, latent_pi: th.Tensor) -> Distribution:\n      \"\"\"\n      Retrieve action distribution given the latent codes.\n\n      :param latent_pi: Latent code for the actor\n      :return: Action distribution\n      \"\"\"\n      mean_actions = self.action_net(latent_pi)\n\n      if isinstance(self.action_dist, DiagGaussianDistribution):\n          return self.action_dist.proba_distribution(mean_actions, self.log_std)\n      elif isinstance(self.action_dist, CategoricalDistribution):\n          # Here mean_actions are the logits before the softmax\n          return self.action_dist.proba_distribution(action_logits=mean_actions)\n      elif isinstance(self.action_dist, MultiCategoricalDistribution):\n          # Here mean_actions are the flattened logits\n          return self.action_dist.proba_distribution(action_logits=mean_actions)\n      elif isinstance(self.action_dist, BernoulliDistribution):\n          # Here mean_actions are the logits (before rounding to get the binary actions)\n          return self.action_dist.proba_distribution(action_logits=mean_actions)\n      elif isinstance(self.action_dist, StateDependentNoiseDistribution):\n          return self.action_dist.proba_distribution(mean_actions, self.log_std, latent_pi)\n      else:\n          raise ValueError(\"Invalid action distribution\")\n\nContinuous actions\nFor continuous actions, the distribution is parameterized a diagonal gaussian:\n\nthe mean is the value produced by the Action Net (size = action size)\nthe deviation is a separate learnable parameter (size = 1, same value for all dimensions)\n\nSampling is done using the same reparameterization trick as in Variational Autoencoders: sample the standard normal, then multiply with deviation and add mean.\nDuring evaluation runs, when we want the most likely action and not a sample, we simply take the output of the Action Net, i.e. the mean action.\nDuring our simulation, choosing the next step is therefore choosing a point from a gaussian cloud:\n\n\n\n\n\nDiscrete actions\nFor discrete actions, the distribution is a categorical distribution\n\nAction Net produces directly the probabilities (or logits) of every action (vector size = action size)\nsampling is done with PyTorch."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]