---
title: "Ensemble scoring review"
date: "2022-11-14"
categories: [paper, anomaly, scoring, brainstorming]
description: 'Combining multiple estimator scores into a common ensenble'
image: 'img/2022-11-14-09-20-56.png'
---


A quick overview of some papers about normalizing and combining scores.

## Krieger2011: Interpreting and Unifying Outlier Scores

> InCollection (Kriegel2011) \
> Kriegel, H.-P.; Kroger, P.; Schubert, E. & Zimek, A. \
> Interpreting and Unifying Outlier Scores \
> Society for Industrial and Applied Mathematics, 2011, 13-24 \

- Different (simple) regularizations and normalizations
- **Regularization** = 0 to infinity, with increasing values = more outlying
- **Normalization** = 0 to 1, with increasing values = more outlying

- Typical: **Gaussian scaling**
  - is = probability (X < value) for a standard normal with mean and dev as the scores (1/2(1+erf()) formula)
  - implemented in PyOD as predict_proba(X, method='**unify**')

## Zimek2014: Ensembles for unsupervised outlier detection: challenges and research questions
> Article (Zimek2014)\
> Zimek, A.; Campello, R. J. & Sander, J.\
> Ensembles for unsupervised outlier detection: challenges and research questions\
> ACM SIGKDD Explorations Newsletter, 2014, 15, 11-22

- Discussions, but no clear solution to take home

- Simple **model selection**:

  - first takes the union of the top k points of all results as preliminary outliers
  - Then the ensemble is composed, starting with the result that is closest to this consensus result.
  - Next the remaining outlier detectors are sorted by the lowest correlation to the result of the current ensemble
    (initially, the ensemble consists only of one outlier detector) and test if including the next detector would improve
    the correlation of the ensemble result with the (preliminary) target vector (i.e., the estimated ground truth).

  ![](img/2022-11-14-09-20-56.png)